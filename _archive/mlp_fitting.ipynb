{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verschiende (absolut unnötige!) Experimente mit MLPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now build a pytorch pipeline to predict sales based on only weather data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# define a dataset class\n",
    "class SalesDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.X = df[[\"temperature_mean\", \"temperature_min\", \"temperature_max\", \"precipitation\", \"sunshine_duration\"]].values\n",
    "        self.y = df[\"Getränke_sales\"].values.reshape(-1, 1)\n",
    "       \n",
    "        # normalize the data\n",
    "        self.X = (self.X - self.X.mean(axis=0)) / self.X.std(axis=0)\n",
    "        mu = self.y.mean(axis=0)\n",
    "        sigma = self.y.std(axis=0)\n",
    "        self.y = (self.y - mu) / sigma\n",
    "        print(\"Mean: {}, Std: {}\".format(mu, sigma))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# split the data into train and test set\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# create the dataset objects with normalized data\n",
    "print(\"Train data\")\n",
    "train_dataset = SalesDataset(train_df)\n",
    "print(\"Test data\")\n",
    "test_dataset = SalesDataset(test_df)\n",
    "\n",
    "# create the dataloader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# define the model parameters\n",
    "input_size = 5\n",
    "hidden_size = 8\n",
    "output_size = 1\n",
    "\n",
    "# define the model\n",
    "class SalesModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SalesModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# create the model object\n",
    "model = SalesModel()\n",
    "\n",
    "# define the loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "# train the model and visualize the loss\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X.float())\n",
    "        loss = criterion(y_pred, y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            y_pred = model(X.float())\n",
    "            loss = criterion(y_pred, y.float())\n",
    "            test_loss += loss.item()\n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        print(\"Best loss: {:.2f}\".format(best_loss))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch: {}, Train Loss: {:.2f}, Test Loss: {:.2f}\".format(epoch, train_loss, test_loss))\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    \n",
    "   \n",
    "    \n",
    "print(\"Best loss: {:.2f}\".format(best_loss))\n",
    "# plot the loss\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "model1 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a seconde dataset class to predict sales with the day of the week\n",
    "class SalesDataset2(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df \n",
    "        self.X = {\"weather\": df[[\"temperature_mean\", \"temperature_min\", \"temperature_max\", \"precipitation\", \"sunshine_duration\"]].values, \n",
    "                    \"date\": pd.get_dummies(df[\"day_of_week\"]).values}\n",
    "        self.y = df[\"Getränke_sales\"].values.reshape(-1, 1)\n",
    "       \n",
    "        # normalize the data (X is a dictionary, so we need to normalize each column separately\n",
    "        self.X[\"weather\"] = (self.X[\"weather\"] - self.X[\"weather\"].mean(axis=0)) / self.X[\"weather\"].std(axis=0)\n",
    "        mu = self.y.mean(axis=0)\n",
    "        sigma = self.y.std(axis=0)\n",
    "        self.y = (self.y - mu) / sigma\n",
    "        print(\"Mean: {}, Std: {}\".format(mu, sigma))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[\"weather\"][idx], self.X[\"date\"][idx], self.y[idx]\n",
    "\n",
    "# split the data into train and test set\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# create the dataset objects with normalized data\n",
    "print(\"Train data\")\n",
    "train_dataset = SalesDataset2(train_df)\n",
    "print(\"Test data\")\n",
    "test_dataset = SalesDataset2(test_df)\n",
    "\n",
    "# create the dataloader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# define the model parameters\n",
    "input_size_weather = 5\n",
    "input_size_date = 7\n",
    "hidden_size = 8\n",
    "output_size = 1\n",
    "\n",
    "# define the model\n",
    "class SalesModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SalesModel2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size_weather, hidden_size)\n",
    "        self.fc2 = nn.Linear(input_size_date, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size*2,  hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x_weather, x_date):\n",
    "        x_weather = F.relu(self.fc1(x_weather))\n",
    "        x_date = F.relu(self.fc2(x_date))\n",
    "        x = torch.cat((x_weather, x_date), dim=1)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# create the model object\n",
    "model = SalesModel2()\n",
    "\n",
    "# define the loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "# train the model and visualize the loss\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    model.train()\n",
    "    for X_weather, X_date, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_weather.float(), X_date.float())\n",
    "        loss = criterion(y_pred, y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_weather, X_date, y in test_loader:\n",
    "            y_pred = model(X_weather.float(), X_date.float())\n",
    "            loss = criterion(y_pred, y.float())\n",
    "            test_loss += loss.item()\n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        print(\"Best loss: {:.2f}\".format(best_loss))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch: {}, Train Loss: {:.2f}, Test Loss: {:.2f}\".format(epoch, train_loss, test_loss))\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "\n",
    "print(\"Best loss: {:.2f}\".format(best_loss))\n",
    "# plot the loss\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "model2 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a third dataset class to predict sales with only the day of the week\n",
    "class SalesDataset3(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df \n",
    "        self.X = pd.get_dummies(df[\"day_of_week\"]).values\n",
    "        self.y = df[\"Getränke_sales\"].values.reshape(-1, 1)\n",
    "       \n",
    "        # normalize the data\n",
    "        mu = self.y.mean(axis=0)\n",
    "        sigma = self.y.std(axis=0)\n",
    "        self.y = (self.y - mu) / sigma\n",
    "        print(\"Mean: {}, Std: {}\".format(mu, sigma))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# split the data into train and test set\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# create the dataset objects with normalized data\n",
    "print(\"Train data\")\n",
    "train_dataset = SalesDataset3(train_df)\n",
    "print(\"Test data\")\n",
    "test_dataset = SalesDataset3(test_df)\n",
    "\n",
    "# create the dataloader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# define the model parameters\n",
    "input_size = 7\n",
    "hidden_size = 32\n",
    "output_size = 1\n",
    "\n",
    "# define the model\n",
    "class SalesModel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SalesModel3, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# create the model object\n",
    "model = SalesModel3()\n",
    "\n",
    "# define the loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "# train the model and visualize the loss\n",
    "epochs = 100\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X.float())\n",
    "        loss = criterion(y_pred, y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            y_pred = model(X.float())\n",
    "            loss = criterion(y_pred, y.float())\n",
    "            test_loss += loss.item()\n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        print(\"Best loss: {:.2f}\".format(best_loss))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch: {}, Train Loss: {:.2f}, Test Loss: {:.2f}\".format(epoch, train_loss, test_loss))\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "\n",
    "print(\"Best loss: {:.2f}\".format(best_loss))\n",
    "# plot the loss\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "model3 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SalesDataset2(df)\n",
    "day = 144+7\n",
    "print(dataset.X[\"date\"][day])\n",
    "print(dataset.X[\"weather\"][day])\n",
    "print(dataset.y[day])\n",
    "print(df[day:day+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test manually to see if the day of the week makes a difference in the prediction\n",
    "\n",
    "\n",
    "pred1 = model1(torch.tensor([1.59759539,  1.34599214,  1.56808058, -0.40700749,  1.53056742]).float().unsqueeze(0))\n",
    "pred2 = model2(torch.tensor([1.59759539,  1.34599214,  1.56808058, -0.40700749,  1.53056742]).float().unsqueeze(0), torch.tensor([0, 0, 0, 0, 0, 0, 1]).float().unsqueeze(0))\n",
    "pred3 = model3(torch.tensor([0, 0, 0, 0, 0, 0, 1]).float().unsqueeze(0))\n",
    "print(pred1)\n",
    "print(pred2)\n",
    "print(pred3)\n",
    "# un-normalize the data\n",
    "mu = 949.91726592\n",
    "sigma = 404.25934273\n",
    "pred1 = pred1.item() * sigma + mu\n",
    "pred2 = pred2.item() * sigma + mu\n",
    "pred3 = pred3.item() * sigma + mu\n",
    "\n",
    "print(\"Prediction 1: {:.2f}\".format(pred1))\n",
    "print(\"Prediction 2: {:.2f}\".format(pred2))\n",
    "print(\"Prediction 3: {:.2f}\".format(pred3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('PytorchGeometric')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b264b2ac6437c9bf059af297d6e83aaee783728e002e0b2ed5d328e2da20d4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
